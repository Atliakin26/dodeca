AFTER REFACTORING - Post-DerivedCore Split
===========================================

Top LLVM IR Contributors from DerivedIngredient/DerivedCore:
------------------------------------------------------------
  337,041 lines (17.1% of total) - DerivedCore::access_scoped_erased::{{closure}} - 73 copies
   23,480 lines ( 1.2% of total) - save_records::{{closure}} - 27 copies
   17,240 lines ( 0.9% of total) - get::{{closure}} - 46 copies
   13,878 lines ( 0.7% of total) - restore_runtime_state::{{closure}} - 27 copies
   12,177 lines ( 0.6% of total) - snapshot_cells_deep::{{closure}} - 27 copies

Total LLVM IR: 1,967,782 lines across 38,888 function copies

Comparison to BEFORE:
---------------------
  BEFORE: 234,836 lines (12.0%) - 50 copies
  AFTER:  337,041 lines (17.1%) - 73 copies
  
  CHANGE: +102,205 lines (+43.5% MORE IR!)
          +23 copies (46% MORE monomorphization!)

REGRESSION - The refactoring MADE IT WORSE!

Root Cause Analysis:
-------------------
The state machine moved from impl<DB,K,V> DerivedIngredient to impl DerivedCore,
BUT it's still generic over F (the future type):

  async fn access_scoped_erased<DB, F>(...)

Each query passes a different closure type for F, so Rust still monomorphizes
the function body for every unique F type. We now have MORE copies (73 vs 50)
because:

1. Each (DB, K, V) combination creates a different closure type
2. The closure captures different types based on K and V
3. More complex closures in the refactored version may create more instantiations

The non-generic DerivedCore struct does NOT help if the methods are still generic
over type parameters!

Next Steps:
-----------
To actually fix this, we need to make compute_erased use a trait object or
other type-erased mechanism, not a generic F parameter. The function signature
needs to be:

  async fn access_scoped_erased(
      &self,
      db: &dyn IngredientLookup,
      requested: DynKey,
      want_value: bool,
      compute_erased: Box<dyn Fn() -> BoxFuture<'_, PicanteResult<Arc<dyn Any>>>>,
  )

But this introduces lifetime and boxing complexity that needs careful design.

Build Time Measurements:
------------------------
Clean build time: 26.71s (wall clock)
  - CPU time: 105.34s user + 5.94s system
  - Parallelism: ~415% (4x cores utilized)

Comparison to BEFORE:
  BEFORE: 25.53s wall, 119.76s user (501% parallel)
  AFTER:  26.71s wall, 105.34s user (415% parallel)
  
  Wall time: +1.18s (+4.6% SLOWER)
  CPU time: -14.42s user (-12% improvement, but worse parallelism)

The build is slightly slower in wall-clock time despite using less total CPU.
This suggests the increased IR size (337k vs 235k lines) offset any potential
gains from the refactoring.
